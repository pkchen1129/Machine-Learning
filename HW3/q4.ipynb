{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:GS_py37_tf_keras]","language":"python","name":"conda-env-GS_py37_tf_keras-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"q4.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"lYKoHGcSUAlm","colab_type":"text"},"source":["Remember to change the load data directory"]},{"cell_type":"code","metadata":{"id":"4D0wd-mY3xc6","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Instruction: use these hyperparameters for both (b) and (d)\n","eta = 0.5\n","C = 5\n","iterNums = [5, 50, 100, 1000, 5000, 6000]\n","\n","def svm_train_bgd(matrix, label, nIter):\n","    # Implement your algorithm and return\n","    state = {}\n","    N, D = matrix.shape\n","    w = np.zeros((4,1))\n","    b = 0.0\n","    ############################\n","    # Implement your code here # \n","    \n","    for i in range(nIter):\n","      alpha = eta/(1 + (i+1)*eta)\n","      A = np.where(np.multiply(label , ( matrix @ w + b) ) < 1 , 1 , 0 ) #decision , one or zero\n","      w_grad = w - C * matrix.T @ np.multiply(A,label) #(4,1)\n","      b_grad = - C * sum(np.multiply(A,label)) #(1,1)\n","      w -= alpha * w_grad\n","      b -= 0.01 * alpha * b_grad\n","\n","    ############################\n","    state = w,b\n","    # print(state[0])\n","    return state\n","\n","def svm_train_sgd(matrix, label, nIter):\n","    # Implement your algorithm and return\n","    state = {}\n","    N, D = matrix.shape\n","    w = np.zeros((4,1))\n","    A = np.zeros((1,1))\n","    b = 0.0\n","    B = b * np.zeros((N,1))\n","    for j in range(nIter): \n","      for i in range(N):\n","        alpha = eta/(1 + (j+1)*eta) \n","        M = np.array([matrix[i,:]])\n","        A = np.where( label[i] * (w.T) @ matrix[i,:].T + b  < 1 , 1 , 0 ) #decision , one or zero\n","        w_grad = w/N - C * A * label[i] * M.T #(4,1)\n","        b_grad = - C * A * label[i] #(1,1)\n","        w -= alpha * w_grad\n","        b -= 0.01 * alpha * b_grad\n","    state = w,b\n","    ############################\n","    # Implement your code here #\n","    ############################\n","    return state\n","\n","def svm_test(matrix, state):\n","    # Classify each test data as +1 or -1\n","    output = np.ones( (matrix.shape[0], 1) )\n","    \n","    ############################\n","    # Implement your code here #\n","    ############################\n","    # a = test_x @ state[0]\n","    # print(a.shape)\n","    output =   matrix @ state[0] + state[1] * np.ones((matrix.shape[0],1)) #(24,1)\n","    \n","    return output\n","\n","def evaluate(output, label, nIter):\n","    # Use the code below to obtain the accuracy of your algorithm\n","    accuracy = (label * output > 0).sum() * 1. / len(output)\n","    print('[Iter {:4d}: accuracy = {:2.4f}%'.format(nIter, 100*accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ha6iX-Y3xdC","colab_type":"code","outputId":"92f84ff2-2ead-4da2-ea48-6c3900b675a0","executionInfo":{"status":"ok","timestamp":1582592273904,"user_tz":300,"elapsed":254,"user":{"displayName":"Po-Kang Chen","photoUrl":"","userId":"03832949950970875412"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Note1: label is {-1, +1}\n","# Note2: data matrix shape  = [Ndata, 4], Ndata = 76\n","# Note3: label matrix shape = [Ndata, 1]\n","\n","# Load data\n","# q4_data = np.load('q4_data/q4_data.npy', allow_pickle=True).item()\n","q4_data = np.load('q4_data/q4_data.npy', allow_pickle=True).item()\n","train_x = q4_data['q4x_train'] #(76, 4)\n","train_y = q4_data['q4y_train']\n","test_x = q4_data['q4x_test'] #24,4\n","test_y = q4_data['q4y_test'] #24,1"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(76, 4)\n","(24, 4)\n","(24, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hokrJWbI82rp","colab_type":"text"},"source":["(b) Implement SVM using **batch gradient descent**. Print out the followings:\n","\n","*   Parameter w\n","*   Parameter b\n","*   Test accuracy (%)"]},{"cell_type":"code","metadata":{"id":"kQYkcSk98uUW","colab_type":"code","outputId":"ad3005e0-5099-464c-e33b-b1532869e242","executionInfo":{"status":"ok","timestamp":1582602209183,"user_tz":300,"elapsed":1626,"user":{"displayName":"Po-Kang Chen","photoUrl":"","userId":"03832949950970875412"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["for nIter in iterNums:\n","  # Train\n","  # print(nIter)\n","  state = svm_train_bgd(train_x, train_y, nIter)\n","  w = state[0]\n","  b = state[1]\n","  print(\"w = \",w.T)\n","  print(\"b = \",b)\n","\n","  # Test and evluate\n","  prediction = svm_test(test_x, state)\n","  evaluate(prediction, test_y, nIter)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["w =  [[ 96.         -36.64285714 233.57142857  88.28571429]]\n","b =  [-0.06892857]\n","[Iter    5: accuracy = 54.1667%\n","w =  [[ -1.98076923 -11.71153846  25.35576923  11.32692308]]\n","b =  [-0.28672539]\n","[Iter   50: accuracy = 95.8333%\n","w =  [[-1.99019608 -4.81862745 11.45098039  5.74019608]]\n","b =  [-0.29568526]\n","[Iter  100: accuracy = 95.8333%\n","w =  [[-0.499501   -0.3243513   1.05538922  1.28293413]]\n","b =  [-0.31806329]\n","[Iter 1000: accuracy = 95.8333%\n","w =  [[-0.3517593  -0.2779888   0.88644542  1.00329868]]\n","b =  [-0.3329032]\n","[Iter 5000: accuracy = 95.8333%\n","w =  [[-0.33655448 -0.28065645  0.89411863  0.98642119]]\n","b =  [-0.33432381]\n","[Iter 6000: accuracy = 95.8333%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZcgdTdAp8_Zv","colab_type":"text"},"source":["(d) Implement SVM using **stochastic gradient descent**. Print out the followings:\n","\n","*   Parameter w\n","*   Parameter b\n","*   Test accuracy (%)\n","\n","[Note: use the same hyperparameters as (b)]\n","\n","[Note: if you implement it correctly, the running time will be ~15 sec]"]},{"cell_type":"code","metadata":{"id":"DkDUnCNz9G2S","colab_type":"code","outputId":"16f07b93-577e-4dfd-c541-76363ac60ac0","executionInfo":{"status":"ok","timestamp":1582603535993,"user_tz":300,"elapsed":23537,"user":{"displayName":"Po-Kang Chen","photoUrl":"","userId":"03832949950970875412"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["for nIter in iterNums:\n","  # Train\n","  state = svm_train_sgd(train_x, train_y, nIter)\n","  w = state[0]\n","  b = state[1]\n","  print(\"w = \",w.T)\n","  print(\"b = \",b)\n","\n","  # Test and evluate\n","  prediction = svm_test(test_x, state)\n","  evaluate(prediction, test_y, nIter)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["w =  [[-1.60513517 -2.82975568  7.75514067  4.70009547]]\n","b =  [-0.03916667]\n","[Iter    5: accuracy = 95.8333%\n","w =  [[-1.57751374 -0.28825955  2.67365117  2.87843094]]\n","b =  [-0.07070155]\n","[Iter   50: accuracy = 95.8333%\n","w =  [[-1.3205845  -0.03813763  1.82861082  2.35350451]]\n","b =  [-0.07804253]\n","[Iter  100: accuracy = 95.8333%\n","w =  [[-0.57038277 -0.22985423  1.05386375  1.23410777]]\n","b =  [-0.10526065]\n","[Iter 1000: accuracy = 95.8333%\n","w =  [[-0.47823705 -0.29816286  0.98836263  1.17408872]]\n","b =  [-0.12475633]\n","[Iter 5000: accuracy = 95.8333%\n","w =  [[-0.49779203 -0.28000682  1.00578787  1.18060628]]\n","b =  [-0.12631455]\n","[Iter 6000: accuracy = 95.8333%\n"],"name":"stdout"}]}]}